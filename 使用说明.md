# Ollama WebUI 使用说明

## 1. 项目介绍

Ollama WebUI 是一个基于 Web 浏览器的 Ollama 大语言模型交互界面，提供了直观、美观的用户界面，支持实时流式对话、多格式文件上传、对话历史管理等功能。

### 主要特点
- ✅ 实时流式对话，响应迅速
- ✅ 支持多种文件格式上传（TXT、DOC、DOCX、PDF、JPG、JPEG、PNG、GIF、BMP、WEBP）
- ✅ 支持图片分析（多模态模型）
- ✅ 对话历史自动保存，支持导出和导入
- ✅ 历史记录导航标记，方便回溯
- ✅ 支持思考模式（显示 AI 思考过程）
- ✅ 自动获取可用模型列表，下拉选择
- ✅ 现代美观的界面设计
- ✅ 响应式布局，适配不同屏幕尺寸

## 2. 系统要求

### 2.1 硬件要求
- 处理器：至少 2 核 CPU
- 内存：至少 4GB RAM（根据使用的模型大小可能需要更多）
- 存储空间：至少 10GB 可用空间（用于存储模型）

### 2.2 软件要求
- **Ollama 服务**：必须安装并运行 Ollama 服务
- **浏览器**：推荐使用现代浏览器
  - Chrome 80+ 或 Firefox 75+ 或 Edge 80+
- **本地服务器**（可选）：用于启动 Web 界面
  - Python 3.6+ 或 Node.js 12+ 或 PHP 7.0+

## 3. 安装和配置

### 3.1 安装 Ollama
1. 从 [Ollama 官网](https://ollama.com/) 下载并安装 Ollama
2. 安装完成后，Ollama 服务会自动启动

### 3.2 拉取模型
打开命令提示符（CMD）或 PowerShell，运行以下命令拉取所需模型：

```bash
# 例如，拉取 qwen3:30b 模型
ollama run qwen3:30b
```

### 3.3 配置 CORS
为了让 Web 界面能够正常与 Ollama API 通信，需要配置 CORS：

#### Windows 用户
- 方法 1：运行项目根目录下的 `setup_cors.bat` 脚本
- 方法 2：手动设置环境变量
  - 在 PowerShell 中运行：
    ```powershell
    $env:OLLAMA_ORIGINS="*"
    ```
  - 或在 CMD 中运行：
    ```cmd
    set OLLAMA_ORIGINS=*
    ```

#### Linux/Mac 用户
在终端中运行：
```bash
export OLLAMA_ORIGINS="*"
```

### 3.4 重启 Ollama 服务
配置完成后，需要重启 Ollama 服务以应用更改：

- Windows：在任务管理器中找到 Ollama 服务并重启
- Linux/Mac：使用系统服务管理命令重启

## 4. 启动方式

### 4.1 使用本地服务器（推荐）

#### Python 3
```bash
# 在项目根目录下运行
python -m http.server 8000
```

#### Node.js
```bash
# 在项目根目录下运行
npx http-server -p 8000
```

#### PHP
```bash
# 在项目根目录下运行
php -S localhost:8000
```

### 4.2 直接打开 HTML 文件
某些浏览器可能允许直接打开 `Ollama_WebUI.html` 文件，但可能会遇到跨域问题。

### 4.3 访问界面
启动服务器后，在浏览器中访问：
```
http://localhost:8000/Ollama_WebUI.html
```

## 5. 界面介绍

### 5.1 顶部栏
- **项目标题**：显示 "Ollama WebUI"
- **设置按钮**：点击打开设置面板，可配置模型和 API 地址

### 5.2 主对话区
- **消息列表**：显示用户和 AI 的对话内容
- **历史导航标记**：显示历史对话的标记，点击可快速跳转

### 5.3 输入区域
- **消息输入框**：输入文本消息
- **文件上传区域**：点击可选择文件上传
- **上传文件列表**：显示已上传的文件
- **思考模式开关**：切换是否使用思考模式
- **发送按钮**：发送消息

## 6. 功能使用说明

### 6.1 基本对话
1. 在输入框中输入您的问题
2. 点击「发送」按钮或按 Enter 键发送
3. 等待 AI 回复（实时流式显示）
4. 继续输入新的问题进行多轮对话

### 6.2 文件上传
1. 点击输入区域上方的「选择文件」按钮
2. 在文件选择对话框中选择要上传的文件（支持 TXT、DOC、DOCX、PDF、JPG、JPEG、PNG、GIF、BMP、WEBP）
3. 文件会自动解析并添加到对话内容中
4. 点击「发送」按钮发送包含文件内容的消息

**支持的文件格式**：
- 文档格式：TXT、DOC、DOCX、PDF
- 图片格式：JPG、JPEG、PNG、GIF、BMP、WEBP

**注意事项**：
- 图片文件会以 Base64 编码形式发送给 AI 进行分析
- 大文件可能会影响响应速度
- 建议单个文件大小不超过 10MB

### 6.3 对话取消
在 AI 回复过程中，点击发送按钮（此时会显示为停止图标）可取消当前对话。

### 6.4 新对话
点击设置面板中的「新对话」按钮，可清空当前对话历史，开始新的对话。

### 6.5 历史记录管理
- **自动保存**：对话历史会自动保存到浏览器本地存储
- **导出历史**：点击设置面板中的「导出历史」按钮，可将对话历史导出为 JSON 文件
- **导入历史**：点击设置面板中的「导入历史」按钮，可从 JSON 文件导入对话历史

### 6.6 思考模式
1. 点击顶部栏的思考按钮（💭图标）开启/关闭思考模式
2. 开启后，AI 会在回复前显示其思考过程
3. 思考内容会以可折叠的形式显示在回复上方
4. 点击思考过程标题可以展开或折叠思考内容

**思考模式特点**：
- 思考内容字号较小，便于区分
- 支持折叠/展开，节省界面空间
- 思考内容会随对话历史一起保存

**注意事项**：
- 需要使用支持思考功能的模型（如 DeepSeek-R1 等）
- 开启思考模式可能会增加响应时间
- 不是所有模型都支持思考功能

### 6.7 模型和 API 配置
1. 点击顶部栏的设置按钮打开设置面板
2. 在「模型」下拉列表中选择要使用的模型
3. 在「API 地址」输入框中输入 Ollama API 地址（默认为 "http://localhost:11434/api/chat"）
4. 点击「保存设置」按钮保存配置

**模型选择说明**：
- 打开设置面板时会自动从 Ollama 获取可用模型列表
- 所有已安装的模型都会显示在下拉列表中
- 当前使用的模型会被自动选中
- 如果模型列表加载失败，会显示"加载失败"提示

**模型切换说明**：
- 点击保存后，设置面板会自动关闭
- 界面会显示"正在切换模型"的提示
- 模型切换成功后会显示确认消息
- 切换模型不会清空当前对话历史

**注意事项**：
- 确保已安装要切换的模型（使用 `ollama pull` 命令）
- 模型切换可能需要几秒钟时间
- 切换后可以继续当前对话
- 如果模型列表为空，请检查 Ollama 服务是否正常运行

## 7. 常见问题和解决方案

### 7.1 403 错误
**问题**：浏览器控制台显示 403 Forbidden 错误
**原因**：CORS 配置不正确
**解决方案**：
- 运行 `setup_cors.bat` 脚本
- 或手动设置环境变量：
  ```powershell
  # PowerShell
  $env:OLLAMA_ORIGINS="*"
  
  # CMD
  set OLLAMA_ORIGINS=*
  ```
- 重启 Ollama 服务

### 7.2 404 错误
**问题**：浏览器控制台显示 404 Not Found 错误
**原因**：模型未找到
**解决方案**：
- 确保已拉取对应的模型：`ollama run 模型名称`
- 检查模型名称是否输入正确

### 7.3 对话响应缓慢
**问题**：AI 回复速度较慢
**解决方案**：
- 检查网络连接是否稳定
- 尝试使用较小的模型
- 减少一次发送的内容量
- 确保 Ollama 服务运行正常

### 7.4 文件上传失败
**问题**：文件上传后无法解析或发送
**解决方案**：
- 检查文件格式是否支持（支持 TXT、DOC、DOCX、PDF、JPG、JPEG、PNG、GIF、BMP、WEBP）
- 确保文件大小适中（建议不超过 10MB）
- 检查浏览器控制台是否有错误信息

### 7.5 思考模式不显示
**问题**：开启思考模式后，AI 回复中没有显示思考内容
**解决方案**：
- 确保使用的模型支持思考功能（如 DeepSeek-R1 等）
- 检查思考模式按钮是否已激活（按钮会变色）
- 不是所有模型都支持思考功能，请查看模型文档

### 7.6 模型切换失败
**问题**：切换模型后无法正常对话
**解决方案**：
- 确保新模型已安装：`ollama pull 模型名称`
- 检查模型名称是否正确
- 确保模型与当前对话兼容
- 如果问题持续，尝试重新开始新对话

### 7.7 历史记录丢失
**问题**：对话历史突然丢失
**原因**：浏览器本地存储被清除
**解决方案**：
- 定期使用导出功能备份对话历史
- 避免使用浏览器的隐私模式

## 8. 故障排除

### 8.1 检查 Ollama 服务状态
1. 打开命令提示符（CMD）或 PowerShell
2. 运行 `ollama list` 命令，查看已安装的模型
3. 如果命令执行失败，说明 Ollama 服务未运行，需要启动服务

### 8.2 检查 API 连接
1. 在浏览器中访问 `http://localhost:11434/api/tags`
2. 如果能看到模型列表，说明 API 连接正常
3. 如果无法访问，检查 Ollama 服务是否运行，以及 API 地址是否正确

### 8.3 浏览器控制台调试
1. 在浏览器中按 F12 打开开发者工具
2. 切换到「控制台」选项卡
3. 查看是否有错误信息
4. 根据错误信息进行相应的排查

## 9. 高级配置

### 9.1 自定义模型路径
在 Windows 中，可以设置自定义模型路径：

```cmd
setx OLLAMA_MODELS "D:\Models"
```

### 9.2 调整 Ollama 服务配置
根据需要，可以调整 Ollama 服务的配置，例如：

- 增加 Ollama 服务的内存限制
- 调整模型加载策略

具体配置方法请参考 Ollama 官方文档。

## 10. 维护和更新

### 10.1 定期维护
- **更新模型**：定期运行 `ollama pull 模型名称` 更新模型
- **备份对话历史**：定期导出对话历史，避免数据丢失
- **清理缓存**：如果界面响应缓慢，可以尝试清理浏览器缓存

### 10.2 更新 WebUI
1. 下载最新版本的 WebUI 文件
2. 替换项目目录中的对应文件
3. 刷新浏览器页面

## 11. 技术支持

如果遇到无法解决的问题，可以：

1. 查看浏览器控制台的错误信息
2. 检查 Ollama 服务的日志
3. 参考 Ollama 官方文档

## 12. 版本信息

- **文档版本**：1.0
- **最后更新**：2026-01-28
- **适用项目**：Ollama WebUI v1.0

---
